{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, ConfusionMatrixMetric\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating aschoplex_T1...\n",
      "Evaluating aschoplex_FLAIR...\n",
      "Evaluating aschoplex_T1xFLAIR...\n",
      "Evaluating aschoplex_T1_FLAIR_T1xFLAIRmask...\n",
      "Evaluating phusegplex_T1...\n",
      "Evaluating phusegplex_FLAIR...\n",
      "Evaluating phusegplex_T1xFLAIR...\n",
      "Evaluating umamba_T1...\n",
      "Evaluating umamba_FLAIR...\n",
      "Evaluating umamba_T1xFLAIR...\n",
      "Evaluating umamba_T1_FLAIR_T1xFLAIRmask...\n",
      "                              Model  Mean Dice   Mean HD  Precision    Recall  \\\n",
      "0                      aschoplex_T1   0.915969  1.072893   0.933723  0.889248   \n",
      "1                   aschoplex_FLAIR   0.762849  2.201648   0.839537  0.890027   \n",
      "2                aschoplex_T1xFLAIR   0.810770  1.832458   0.786519  0.878894   \n",
      "3   aschoplex_T1_FLAIR_T1xFLAIRmask   0.826060  1.804438   0.781045  0.879016   \n",
      "4                     phusegplex_T1   0.920008  1.067720   0.793595  0.882736   \n",
      "5                  phusegplex_FLAIR   0.765002  2.182925   0.796140  0.883409   \n",
      "6               phusegplex_T1xFLAIR   0.792209  2.052917   0.784549  0.876540   \n",
      "7                         umamba_T1   0.900137  1.193373   0.790606  0.876252   \n",
      "8                      umamba_FLAIR   0.764692  2.187822   0.791072  0.877061   \n",
      "9                   umamba_T1xFLAIR   0.814515  1.781463   0.783731  0.875690   \n",
      "10     umamba_T1_FLAIR_T1xFLAIRmask   0.825703  1.837645   0.782778  0.875961   \n",
      "\n",
      "    F1 Score Best Dice Worst Dice  Best HD Worst HD  \n",
      "0   0.910855       034        016      004      104  \n",
      "1   0.863788       034        055      005      055  \n",
      "2   0.830139       034        081      005      081  \n",
      "3   0.827137       034        081      005      081  \n",
      "4   0.835785       034        016      004      104  \n",
      "5   0.837502       034        068      005      055  \n",
      "6   0.827996       034        016      005      016  \n",
      "7   0.831225   034.nii    016.nii  004.nii  016.nii  \n",
      "8   0.831848   034.nii    055.nii  005.nii  055.nii  \n",
      "9   0.827162   026.nii    081.nii  005.nii  081.nii  \n",
      "10  0.826752   005.nii    081.nii  005.nii  081.nii  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def extract_prefix(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    if '_' in base_name:\n",
    "        return base_name.split('_')[0]\n",
    "    else:\n",
    "        return os.path.splitext(base_name)[0]\n",
    "\n",
    "    \n",
    "# Function to determine model and modality from pred_folder\n",
    "def get_model_modality(pred_folder):\n",
    "    if 'aschoplex' in pred_folder:\n",
    "        model = 'aschoplex'\n",
    "    elif 'phusegplex' in pred_folder:\n",
    "        model = 'phusegplex'\n",
    "    elif 'umamba' in pred_folder:\n",
    "        model = 'umamba'\n",
    "    else:\n",
    "        model = 'unknown'\n",
    "\n",
    "    if 'T1/' in pred_folder:\n",
    "        modality = 'T1'\n",
    "    elif '_FLAIR/' in pred_folder:\n",
    "        modality = 'FLAIR'\n",
    "    elif 'T1xFLAIR/' in pred_folder:\n",
    "        modality = 'T1xFLAIR'\n",
    "    elif 'T1_FLAIR_T1xFLAIRmask/' in pred_folder:\n",
    "        modality = 'T1_FLAIR_T1xFLAIRmask'\n",
    "    else:\n",
    "        modality = 'unknown'\n",
    "\n",
    "    return f\"{model}_{modality}\"\n",
    "\n",
    "# List of prediction folders\n",
    "pred_folders = [\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/01_aschoplex_from_scratch/working_directory_01_T1/ensemble_output/image_Ts\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/01_aschoplex_from_scratch/working_directory_01_FLAIR/ensemble_output/image_Ts\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/01_aschoplex_from_scratch/working_directory_01_T1xFLAIR/ensemble_output/image_Ts\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/01_aschoplex_from_scratch/working_directory_01_T1_FLAIR_T1xFLAIRmask/ensemble_output/image_Ts\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/02_phusegplex/working_directory_02_T1/ensemble_output/image_Ts\", \n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/02_phusegplex/working_directory_02_FLAIR/ensemble_output/image_Ts\", \n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/02_phusegplex/working_directory_02_T1xFLAIR/ensemble_output/image_Ts\", \n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/umamba_predictions/working_directory_T1/pred_pp\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/umamba_predictions/working_directory_FLAIR/pred_pp\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/umamba_predictions/working_directory_T1xFLAIR/pred_pp\",\n",
    "    \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/umamba_predictions/working_directory_T1_FLAIR_T1xFLAIRmask/pred_pp\"\n",
    "]\n",
    "\n",
    "gt_folder = \"/home/linuxlia/Lia_Masterthesis/data/reference_labels_T1/ref_labelTs\"\n",
    "gt_files = sorted([f for f in os.listdir(gt_folder) if f.endswith('.nii')])\n",
    "ground_truths = [nib.load(os.path.join(gt_folder, f)).get_fdata() for f in gt_files]\n",
    "\n",
    "# Initialize the metrics\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=False, percentile=95)\n",
    "confusion_matrix_metric = ConfusionMatrixMetric(include_background=False, metric_name=[\"precision\", \"recall\", \"f1_score\"], reduction=\"mean\")\n",
    "\n",
    "# List to store the results\n",
    "results_list = []\n",
    "\n",
    "# Loop over each prediction folder\n",
    "for pred_folder in pred_folders:\n",
    "    # Get model and modality\n",
    "    model_modality = get_model_modality(pred_folder)\n",
    "    print(f\"Evaluating {model_modality}...\")\n",
    "    pred_files = sorted([f for f in os.listdir(pred_folder) if f.endswith('.nii.gz')])\n",
    "    predictions = [nib.load(os.path.join(pred_folder, f)).get_fdata() for f in pred_files]\n",
    "\n",
    "    dice_scores = []\n",
    "    hd_distances = []\n",
    "    f1_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Initialize variables to store best and worst segmentations\n",
    "    best_dice_score = -1\n",
    "    worst_dice_score = float('inf')\n",
    "    best_hd_distance = float('inf')\n",
    "    worst_hd_distance = -1\n",
    "\n",
    "    best_dice_filename = None\n",
    "    worst_dice_filename = None\n",
    "    best_hd_filename = None\n",
    "    worst_hd_filename = None\n",
    "\n",
    "    # Compute metrics for each pair of prediction and ground truth\n",
    "    for pred, gt, filename in zip(predictions, ground_truths, pred_files):\n",
    "        pred_tensor = torch.tensor(pred, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "        gt_tensor = torch.tensor(gt, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Check for empty tensors\n",
    "        if torch.sum(pred_tensor) == 0 or torch.sum(gt_tensor) == 0:\n",
    "            print(\"Warning: Empty prediction or ground truth tensor detected.\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure matching shapes\n",
    "        if pred_tensor.shape != gt_tensor.shape:\n",
    "            print(f\"Error: Shape mismatch - pred: {pred_tensor.shape}, gt: {gt_tensor.shape}\")\n",
    "            continue\n",
    "        \n",
    "        # Compute Dice score\n",
    "        dice_score = dice_metric(y_pred=pred_tensor, y=gt_tensor)\n",
    "        mean_dice_score = dice_score.mean().item()\n",
    "        dice_scores.append(mean_dice_score)\n",
    "\n",
    "        # Update best and worst Dice segmentations\n",
    "        if mean_dice_score > best_dice_score:\n",
    "            best_dice_score = mean_dice_score\n",
    "            best_dice_prefix = extract_prefix(filename)\n",
    "        if mean_dice_score < worst_dice_score:\n",
    "            worst_dice_score = mean_dice_score\n",
    "            worst_dice_prefix = extract_prefix(filename)\n",
    "        \n",
    "        # Compute Hausdorff distance\n",
    "        hd_distance = hausdorff_metric(y_pred=pred_tensor, y=gt_tensor)\n",
    "        hd_distances.append(hd_distance.item())\n",
    "\n",
    "        # Update best and worst Hausdorff segmentations\n",
    "        if hd_distance < best_hd_distance:\n",
    "            best_hd_distance = hd_distance.item()\n",
    "            best_hd_prefix = extract_prefix(filename)\n",
    "        if hd_distance > worst_hd_distance:\n",
    "            worst_hd_distance = hd_distance.item()\n",
    "            worst_hd_prefix = extract_prefix(filename)\n",
    "        \n",
    "        # Accumulate confusion matrix results\n",
    "        confusion_matrix_metric(y_pred=pred_tensor, y=gt_tensor)\n",
    "        precision, recall, f1_score = confusion_matrix_metric.aggregate()\n",
    "        \n",
    "        f1_scores.append(f1_score.item())\n",
    "        precisions.append(precision.item())\n",
    "        recalls.append(recall.item())\n",
    "\n",
    "    # Aggregate metrics to get summary statistics\n",
    "    mean_dice = sum(dice_scores) / len(dice_scores)\n",
    "    mean_hd_distance = sum(hd_distances) / len(hd_distances)\n",
    "    mean_precision = sum(precisions) / len(precisions)\n",
    "    mean_recall = sum(recalls) / len(recalls)\n",
    "    mean_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    # Append the results to the list\n",
    "    results_list.append({\n",
    "        \"Model\": model_modality,\n",
    "        \"Mean Dice\": mean_dice,\n",
    "        \"Mean HD\": mean_hd_distance,\n",
    "        \"Precision\": mean_precision,\n",
    "        \"Recall\": mean_recall,\n",
    "        \"F1 Score\": mean_f1_score,\n",
    "        \"F1 Score\": mean_f1_score,\n",
    "        \"Best Dice\": best_dice_prefix,\n",
    "        \"Worst Dice\": worst_dice_prefix,\n",
    "        \"Best HD\": best_hd_prefix,\n",
    "        \"Worst HD\": worst_hd_prefix\n",
    "    })\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results = pd.DataFrame(results_list)\n",
    "\n",
    "# Print the results table\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "file_path = \"/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/segmentation_metrics_t1_gt.csv\"\n",
    "results.to_csv(file_path, index=False)\n",
    "\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Segmentation Metrics\", dataframe=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Prediction\")\n",
    "plt.imshow(predictions[0][..., int(predictions[0].shape[-1] / 2)], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.imshow(ground_truths[0][..., int(ground_truths[0].shape[-1] / 2)], cmap=\"gray\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
