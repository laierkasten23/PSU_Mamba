{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Ex. Train   Toolbox           Model_fold (Best) Fold  (Best) Dice  \\\n",
       " 0        T1  ASCHOPLEX    DynUnet128dice_0         0.0      0.91775   \n",
       " 1       NaN        NaN    DynUnet128dice_1         0.1      0.90933   \n",
       " 2       NaN        NaN    DynUnet128dice_2         0.2      0.87928   \n",
       " 3       NaN        NaN    DynUnet128dice_3         0.3      0.92123   \n",
       " 4       NaN        NaN  DynUnet128diceCE_0         1.0      0.91426   \n",
       " \n",
       "   (Best) ref Dice / Test: vs train modality Dice  Accuracy Accuracy ref  \\\n",
       " 0                                        0.85008       NaN          NaN   \n",
       " 1                                        0.83785   0.89155      0.83668   \n",
       " 2                                        0.85318   0.92255      0.83006   \n",
       " 3                                        0.81961   0.90863      0.83978   \n",
       " 4                                        0.85039   0.92707      0.84375   \n",
       " \n",
       "         HD   HD ref Val/Test  Mean Model Dice  Std Model Dice  \n",
       " 0  1.05731  1.39338      Val           0.9069          0.0165  \n",
       " 1  1.17019  1.66547      Val              NaN             NaN  \n",
       " 2  1.39675   1.2938      Val              NaN             NaN  \n",
       " 3  1.00000  1.78483      Val              NaN             NaN  \n",
       " 4  1.14319  1.48936      Val           0.9047          0.0160  ,\n",
       "   Ex. Test  Unnamed: 1   T1xFLAIR Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
       " 0      NaN         NaN  Mead Dice    Mean HD  Precision     Recall   F1 Score   \n",
       " 1       T1   ASCHOPLEX     0.8194     2.2687     0.8804     0.7432     0.8051   \n",
       " 2      NaN  PhuSegPlex     0.8198     2.2287      0.878     0.8254     0.8509   \n",
       " 3      NaN      UMAMBA     0.8178     2.1284     0.8788     0.8216     0.8492   \n",
       " 4    FLAIR   ASCHOPLEX     0.8229     2.0951     0.8592     0.7784     0.8166   \n",
       " \n",
       "           T1 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11      FLAIR  \\\n",
       " 0  Mean Dice    Mean HD  Precision      Recall    F1 Score  Mean Dice   \n",
       " 1      0.916     1.0729     0.9337      0.8892      0.9109     0.7722   \n",
       " 2       0.92     1.0677     0.7936      0.8827      0.8358     0.7722   \n",
       " 3     0.9001     1.1934     0.7906      0.8763      0.8312     0.7746   \n",
       " 4     0.7628     2.2016     0.8395        0.89      0.8638     0.8443   \n",
       " \n",
       "   Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
       " 0     Mean HD   Precision      Recall    F1 Score  \n",
       " 1      2.7244      0.8812      0.6558      0.7513  \n",
       " 2      2.5891      0.9093        0.77      0.8339  \n",
       " 3      2.5515      0.9114      0.7571      0.8271  \n",
       " 4      2.2393      0.8871      0.7215      0.7955  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '/home/linuxlia/Lia_Masterthesis/phuse_thesis_2024/thesis_experiments/train_test_results.xlsx'\n",
    "\n",
    "# Load the sheets based on the correct sheet names\n",
    "train_results = pd.read_excel(file_path, sheet_name='Train')\n",
    "test_results = pd.read_excel(file_path, sheet_name='Test')\n",
    "\n",
    "# Display the first few rows of each sheet to understand the structure\n",
    "train_results.head(), test_results.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Ex. Train', 'Toolbox ', 'Model_fold', '(Best) Fold', '(Best) Dice',\n",
       "        '(Best) ref Dice / Test: vs train modality Dice', 'Accuracy',\n",
       "        'Accuracy ref', 'HD', 'HD ref', 'Val/Test', 'Mean Model Dice',\n",
       "        'Std Model Dice'],\n",
       "       dtype='object'),\n",
       " Index(['Ex. Test', 'Unnamed: 1', 'T1xFLAIR', 'Unnamed: 3', 'Unnamed: 4',\n",
       "        'Unnamed: 5', 'Unnamed: 6', 'T1', 'Unnamed: 8', 'Unnamed: 9',\n",
       "        'Unnamed: 10', 'Unnamed: 11', 'FLAIR', 'Unnamed: 13', 'Unnamed: 14',\n",
       "        'Unnamed: 15', 'Unnamed: 16'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.keys(), test_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjusting the column names for the training results dataframe\n",
    "train_dice_scores = train_results[['Ex. Train', 'Toolbox ', '(Best) Dice']].dropna()\n",
    "\n",
    "# Adjusting the column names for the testing results dataframe\n",
    "test_dice_scores = test_results[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 3']].dropna()\n",
    "test_dice_scores.columns = ['Experiment', 'Toolbox', 'Mean Dice Score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dice_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dice_scores\u001b[49m\u001b[38;5;241m.\u001b[39mkeys(), test_dice_scores\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dice_scores' is not defined"
     ]
    }
   ],
   "source": [
    "train_dice_scores.keys(), test_dice_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the training Dice scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "for toolbox in train_dice_scores['Toolbox '].unique():\n",
    "    toolbox_data = train_dice_scores[train_dice_scores['Toolbox '] == toolbox]\n",
    "    plt.plot(toolbox_data['Ex. Train'], toolbox_data['(Best) Dice'], label=f'{toolbox} - Train')\n",
    "\n",
    "plt.title('Training Dice Scores Across Experiments and Toolboxes')\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Best Dice Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the testing Dice scores for different ground truths\n",
    "plt.figure(figsize=(10, 6))\n",
    "for toolbox in test_dice_scores['Toolbox'].unique():\n",
    "    toolbox_data = test_dice_scores[test_dice_scores['Toolbox'] == toolbox]\n",
    "    plt.plot(toolbox_data['Experiment'], toolbox_data['Mean Dice Score'], label=f'{toolbox} - Test')\n",
    "\n",
    "plt.title('Testing Dice Scores Across Experiments and Toolboxes')\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Mean Dice Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
