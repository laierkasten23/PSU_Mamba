bundle_root: null                           # root folder of the fold
ckpt_path: $@bundle_root + '/model'         # location to save checkpoints and logs
mlflow_tracking_uri: $@ckpt_path + '/mlruns/'
mlflow_experiment_name: "Auto3DSeg"

data_file_base_dir: null                    # location of the dataset
data_list_file_path: null                   # location of the file with a list of files image/label in the dataset

modality: mri                               # main image modality, must be one of mri, ct, pet
fold: 0

class_names: null
class_index: null

debug: false
ckpt_save: true
cache_rate: null
roi_size: [180, 240, 240]


auto_scale_allowed: true
auto_scale_batch: true
auto_scale_roi: false
auto_scale_filters: false

quick: false
channels_last: true
validate_final_original_res: true
calc_val_loss: false
amp: true
log_output_file: null
cache_class_indices: null
early_stopping_fraction: 0.001
determ: false
stop_on_lowacc: false

training:
  # hyper-parameters
  amp: true
  determ: false
  input_channels: null
  learning_rate: 0.0002
  num_images_per_batch: 2
  num_iterations: 20000
  num_iterations_per_validation: 500
  num_patches_per_image: 1
  num_sw_batch_size: 2
  output_classes: null
  overlap_ratio: 0.625
  patch_size: null
  patch_size_valid: null
  softmax: true

  loss:
  _target_: DiceCELoss
  include_background: true
  squared_pred: true
  smooth_nr: 0
  smooth_dr: 1.0e-05
  softmax: $not @training#sigmoid
  sigmoid: $@training#sigmoid
  to_onehot_y: $not @training#sigmoid
  batch: true

  optimizer:
  _target_: torch.optim.AdamW
  lr: '@training#learning_rate'
  weight_decay: 1.e-5

  lr_scheduler:
  _target_: monai.optimizers.WarmupCosineSchedule
  optimizer: "$@training#optimizer"
  warmup_steps: $@num_epochs // 10
  t_total: '@num_epochs // @num_epochs_per_validation + 0.1'
  warumup_multiplier: 0.1

batch_size: '@training#num_images_per_batch'

num_epochs: 300
num_warmup_epochs: 3
sigmoid: false
resample: false
resample_resolution: [1, 1, 1]
crop_mode: ratio
normalize_mode: meanstd
intensity_bounds: null

num_epochs_per_validation: null
num_epochs_per_saving: 1
num_workers: 4
num_steps_per_image: null
num_crops_per_image: 1

# fine-tuning
finetune:
  activate: false
  pretrained_ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'"
  enabled: false
  ckpt_name: $@bundle_root + '/model/model.pt'


# validation
validate:
  ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'"
  save_mask: true # before: false 
  log_output_file: "$@bundle_root + '/model_fold' + str(@fold) + '/validation.log'"
  output_path: "$@bundle_root + '/prediction_fold' + str(@fold)" #  $@bundle_root + '/prediction_validation' before
  # invert: true
  # enabled: false


# inference
infer:
  ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'" # $@bundle_root + '/model/model.pt' before
  fast: false
  data_list_key: testing
  log_output_file: "$@bundle_root + '/model_fold' + str(@fold) + '/inference.log'"
  output_path: "$@bundle_root + '/prediction_' + @infer#data_list_key"
  #enabled: false



