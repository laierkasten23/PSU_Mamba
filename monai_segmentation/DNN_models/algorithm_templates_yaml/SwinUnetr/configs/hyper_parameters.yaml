bundle_root: null                           # root folder of the fold
ckpt_path: $@bundle_root + '/model'         # location to save checkpoints and logs
mlflow_tracking_uri: $@ckpt_path + '/mlruns/'
mlflow_experiment_name: "Auto3DSeg"

data_file_base_dir: null                    # location of the dataset
data_list_file_path: null                   # location of the file with a list of files image/label in the dataset

modality: mri                               # main image modality, must be one of mri, ct, pet
fold: 0

class_names: null
class_index: null

debug: false
ckpt_save: true
cache_rate: null
roi_size: [180, 240, 240]
roi_size_valid: null
random_seed: 0

auto_scale_allowed: true
auto_scale_batch: true
auto_scale_roi: false
auto_scale_filters: false
auto_scale_max_epochs: 1000

quick: false
channels_last: true
validate_final_original_res: true
calc_val_loss: false
log_output_file: "$@bundle_root + '/model_fold' + str(@fold) + '/training.log'"
cache_class_indices: null
early_stopping_fraction: 0.001
early_stop_mode: true
early_stop_delta: 0
early_stop_patience: 5
stop_on_lowacc: false

cache_rate: 0                                   # rate at which data is cached during training/val
train_cache_rate: "$@cache_rate"
validate_cache_rate: "$@cache_rate"
show_cache_progress: false

use_pretrain: false

training:
  # hyper-parameters
  amp: true                                     # automatic mixed precision is used for training -Â° speed up training, reduce GPU memory usage
  determ: false
  input_channels: null
  learning_rate: 0.0002
  num_images_per_batch: 2
  num_iterations: 20000
  num_iterations_per_validation: 500
  num_patches_per_image: 1
  num_sw_batch_size: 2
  output_classes: null
  n_cases: null
  overlap_ratio: 0.125
  overlap_ratio_final: 0.625
  patch_size: null
  patch_size_valid: null
  softmax: true

  resample_resolution: null

  transforms:
    resample_resolution: "$@training#resample_resolution"
    lazy_resampling: false

  loss:
    _target_: DiceCELoss
    include_background: true
    squared_pred: true
    smooth_nr: 0
    smooth_dr: 1.0e-05
    softmax: $@training#softmax
    sigmoid: $not @training#softmax
    to_onehot_y: $@training#softmax
    #batch: true

  optimizer:
    _target_: torch.optim.AdamW
    lr: '@training#learning_rate'
    weight_decay: 1.0e-05

  lr_scheduler:
    _target_: monai.optimizers.WarmupCosineSchedule
    optimizer: "$@training#optimizer"
    warmup_steps: $@num_epochs // 100
    t_total: '@num_epochs // @num_epochs_per_validation + 1'
    warumup_multiplier: 0.1

batch_size: '@training#num_images_per_batch'
num_epochs: 300
num_warmup_epochs: 3
resample: false
resample_resolution: [1, 1, 1]
crop_mode: ratio
normalize_mode: meanstd
intensity_bounds: null

num_epochs_per_validation: 5
num_epochs_per_saving: 1
num_workers: 8
num_workers_validation: 2
num_cache_workers: 8
num_steps_per_image: null
num_crops_per_image: 1

# fine-tuning
finetune:
  activate: false
  pretrained_ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'"
  #enabled: false
  #ckpt_name: $@bundle_root + '/model/model.pt'


# validation
validate:
  ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'"
  save_mask: true # before: false 
  log_output_file: "$@bundle_root + '/model_fold' + str(@fold) + '/validation.log'"
  output_path: "$@bundle_root + '/prediction_fold' + str(@fold)" #  $@bundle_root + '/prediction_validation' before
  # invert: true
  # enabled: false


# inference
infer:
  ckpt_name: "$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'" # $@bundle_root + '/model/model.pt' before
  fast: false
  data_list_key: testing
  log_output_file: "$@bundle_root + '/model_fold' + str(@fold) + '/inference.log'"
  output_path: "$@bundle_root + '/prediction_' + @infer#data_list_key"
  #enabled: false



