{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from monai.networks.nets import DynUNet\n",
    "\n",
    "'''\n",
    "create a dynamically configurable model in MONAI and how to load pre-trained weights into the model. \n",
    "It also shows how to calculate the parameters for the model based on the task properties.\n",
    "'''\n",
    "\n",
    "\n",
    "def get_kernels_strides():\n",
    "    \"\"\"\n",
    "    This function is only used for decathlon datasets with the provided patch sizes.\n",
    "    When refering this method for other tasks, please ensure that the patch size for each spatial dimension should\n",
    "    be divisible by the product of all strides in the corresponding dimension.\n",
    "    In addition, the minimal spatial size should have at least one dimension that has twice the size of\n",
    "    the product of all strides. For patch sizes that cannot find suitable strides, an error will be raised.\n",
    "\n",
    "    get the kernel sizes and strides for the DynUNet model. \n",
    "    This function calculates these parameters based on the patch size and spacing for the given task.\n",
    "\n",
    "    \"\"\"\n",
    "    sizes = [180, 240, 240]\n",
    "    spacings = [1.0, 1.0, 1.0],\n",
    "\n",
    "    input_size = sizes\n",
    "    strides, kernels = [], []\n",
    "    while True:\n",
    "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
    "        stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n",
    "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "        if all(s == 1 for s in stride):\n",
    "            break\n",
    "        for idx, (i, j) in enumerate(zip(sizes, stride)):\n",
    "            if i % j != 0:\n",
    "                raise ValueError(\n",
    "                    f\"Patch size is not supported, please try to modify the size {input_size[idx]} in the spatial dimension {idx}.\"\n",
    "                )\n",
    "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "        kernels.append(kernel)\n",
    "        strides.append(stride)\n",
    "\n",
    "    strides.insert(0, len(spacings) * [1])\n",
    "    kernels.append(len(spacings) * [3])\n",
    "    return kernels, strides\n",
    "\n",
    "\n",
    "def get_network(properties, pretrain_path, checkpoint=None):\n",
    "    '''\n",
    "    This function creates a DynUNet model with the given properties and pre-trained weights.\n",
    "    :param properties: a dictionary containing the properties of the task, such as the number of classes, the modality, and the labels.\n",
    "    :param pretrain_path: the path to the pre-trained weights.\n",
    "    :param checkpoint: the name of the checkpoint file.\n",
    "\n",
    "    :return: a DynUNet model with the given properties and pre-trained weights.\n",
    "    '''\n",
    "    n_class = len(properties[\"labels\"])\n",
    "    in_channels = len(properties[\"modality\"])\n",
    "    kernels, strides = get_kernels_strides()\n",
    "\n",
    "    net = DynUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=n_class,\n",
    "        kernel_size=kernels,\n",
    "        strides=strides,\n",
    "        upsample_kernel_size=strides[1:],\n",
    "        norm_name=\"instance\",\n",
    "        deep_supervision=False,\n",
    "        deep_supr_num=1,\n",
    "    )\n",
    "\n",
    "    if checkpoint is not None:\n",
    "        '''\n",
    "        If a checkpoint is provided, it loads the pre-trained weights from the checkpoint file into the model. \n",
    "        If the checkpoint file does not exist, it continues without loading any pre-trained weights.\n",
    "        '''\n",
    "        pretrain_path = os.path.join(pretrain_path, checkpoint)\n",
    "        if os.path.exists(pretrain_path):\n",
    "            net.load_state_dict(torch.load(pretrain_path))\n",
    "            print(\"pretrained checkpoint: {} loaded\".format(pretrain_path))\n",
    "        else:\n",
    "            print(\"no pretrained checkpoint\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
