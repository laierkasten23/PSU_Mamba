{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Script to search for optimal hyperparameter configuration of a model using grid search.\n",
    "\n",
    "It takes an algorithm template folder (containing yaml files) \n",
    "with the following folder structure: \n",
    "\n",
    "algorithm_template_yaml_folder\n",
    "│\n",
    "├── algorithm1\n",
    "│   ├── configs\n",
    "│   │   ├── hyper_parameters.yaml\n",
    "│   │   ├── network.yaml\n",
    "│   │   ├── transforms_infer.yaml\n",
    "│   │   ├── transforms_validate.yaml\n",
    "│   │   └── transforms_train.yaml\n",
    "│   ├── docs\n",
    "│   │   └── algorithm1.md\n",
    "│   └── scripts\n",
    "│   │   ├── __init__.py\n",
    "│   │   ├── infer.py\n",
    "│   │   ├── train.py\n",
    "│   │   └── validate.py\n",
    "│\n",
    "├── algorithm2\n",
    "│   ├── configs\n",
    "...\n",
    "\n",
    "It reads the hyper_parameters.yaml file and performs a grid search over the hyperparameters.\n",
    "This means, it searches for the given arguments in the hyper_parameters.yaml file and makes a grid search in the given range for that argument.\n",
    "It changes the hyperparameters in the hyper_parameters.yaml file and runs the training with the new hyperparameters.\n",
    "It always saves the best hyperparameters in the hyper_parameters.yaml file.\n",
    "\n",
    "The script will run the training script for each hyperparameter configuration and save the results in a csv file.\n",
    "\n",
    "The script will also save the best hyperparameters in the hyper_parameters.yaml file.\n",
    "\n",
    "Arguments:\n",
    "    -t, --template_folder: Path to the algorithm template folder\n",
    "    -hl, --hyperparameter_list: List of hyperparameters to search for\n",
    "    -r, --range: Range of the hyperparameters to search for\n",
    "\n",
    "Example:\n",
    "    python3 grid_search.py -t algorithm_template_yaml_folder -hl hyperparameter1 hyperparameter2 -r 1 2 3 4 5\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def get_hyperparameters(hyperparameter_file):\n",
    "    \"\"\"\n",
    "    Reads the hyperparameters from a YAML file.\n",
    "\n",
    "    Args:\n",
    "        hyperparameter_file (str): The path to the YAML file containing the hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the hyperparameters.\n",
    "\n",
    "    Examples:\n",
    "        >>> get_hyperparameters('configs/hyper_parameters.yaml')\n",
    "        {'learning_rate': 0.001, 'batch_size': 32, 'epochs': 10}\n",
    "    \"\"\"\n",
    "    with open(hyperparameter_file, 'r') as file:\n",
    "        hyperparameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "    # return deepcopy of hyperparameters to avoid changing the original hyperparameters\n",
    "    return deepcopy(hyperparameters)\n",
    "\n",
    "def set_hyperparameters(hyperparameter_file, hyperparameters):\n",
    "    \"\"\"\n",
    "    Set the hyperparameters in a YAML file.\n",
    "\n",
    "    Args:\n",
    "        hyperparameter_file (str): The path to the YAML file to write the hyperparameters to.\n",
    "        hyperparameters (dict): A dictionary containing the hyperparameters to be written.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(hyperparameter_file, 'w') as file:\n",
    "        yaml.dump(hyperparameters, file)\n",
    "\n",
    "def run_training_script(script_path):\n",
    "    # run the training scripts passing the training script path and all the yaml files\n",
    "    subprocess.run(['python3', script_path, 'configs/hyper_parameters.yaml', 'configs/network.yaml', 'configs/transforms_train.yaml', 'configs/transforms_validate.yaml', 'configs/transforms_infer.yaml'])\n",
    "\n",
    "def get_results(results_file):\n",
    "    results = pd.read_csv(results_file)\n",
    "    return results\n",
    "\n",
    "def save_results(results_file, results):\n",
    "    results.to_csv(results_file, index=False)\n",
    "\n",
    "def get_best_hyperparameters(results):\n",
    "    \"\"\"\n",
    "    Returns the best hyperparameters based on the minimum loss value in the results DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        results (pandas.DataFrame): DataFrame containing the hyperparameters and corresponding loss values.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: Series containing the best hyperparameters.\n",
    "\n",
    "    \"\"\"\n",
    "    best_hyperparameters = results.loc[results['loss'].idxmin()]\n",
    "    return best_hyperparameters\n",
    "\n",
    "def grid_search(hyperparameters_file: str, hyperparameters, hyperparameter_list, hyperparameter_range, results_file, script_path):\n",
    "    \"\"\"\n",
    "    Perform a grid search over a range of hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters_file (str): Path to the file containing hyperparameters.\n",
    "        hyperparameters (dict): Dictionary of hyperparameters.\n",
    "        hyperparameter_list (list): List of hyperparameters to be tuned.\n",
    "        hyperparameter_range (list): List of values for each hyperparameter in the grid search.\n",
    "        results_file (str): Path to the file to store the results.\n",
    "        script_path (str): Path to the training script.\n",
    "\n",
    "    Returns:\n",
    "        dict: The best hyperparameters found during the grid search.\n",
    "\n",
    "    \"\"\"\n",
    "    results = get_results(results_file)\n",
    "    for hyperparameter in hyperparameter_list:\n",
    "        for value in hyperparameter_range:\n",
    "            hyperparameters[hyperparameter] = value\n",
    "            set_hyperparameters(hyperparameters_file, hyperparameters)\n",
    "            run_training_script(script_path)\n",
    "            new_results = get_results(results_file)\n",
    "            # TODO: in training script, we need to generate some results\n",
    "            results = pd.concat([results, new_results])\n",
    "            save_results(results_file, results)\n",
    "    best_hyperparameters = get_best_hyperparameters(results)\n",
    "    return best_hyperparameters\n",
    "\n",
    "def main(template_folder, hyperparameter_list, hyperparameter_range, algorithm_list):\n",
    "    \"\"\"\n",
    "    Perform grid search for hyperparameters on each algorithm in the template folder.\n",
    "\n",
    "    Args:\n",
    "        template_folder (str): Path to the folder containing algorithm templates.\n",
    "        hyperparameter_list (list): List of hyperparameters to be tuned.\n",
    "        hyperparameter_range (dict): Dictionary specifying the range of values for each hyperparameter.\n",
    "        algorithm_list (list): List of algorithms to perform grid search on.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    all_algorithms = algorithm_list if algorithm_list is not None else os.listdir(template_folder)\n",
    "\n",
    "    for algorithm in all_algorithms:\n",
    "        algorithm_folder = os.path.join(template_folder, algorithm)\n",
    "        hyperparameters_file = os.path.join(algorithm_folder, 'configs', 'hyper_parameters.yaml')\n",
    "        hyperparameters = get_hyperparameters(hyperparameters_file)\n",
    "        # TODO: adapt results file (might depend on working_dir) \n",
    "        results_file = os.path.join(algorithm_folder, 'results.csv')\n",
    "        script_path = os.path.join(algorithm_folder, 'scripts', 'train.py')\n",
    "        best_hyperparameters = grid_search(hyperparameters_file, hyperparameters, hyperparameter_list, hyperparameter_range, results_file, script_path)\n",
    "        # save the best hyperparameters in the hyperparameters file\n",
    "        set_hyperparameters(hyperparameters_file, best_hyperparameters)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Search for optimal hyperparameter configuration of a model using grid search.')\n",
    "    parser.add_argument('-t', '--template_folder', type=str, help='Path to the algorithm template folder', required=True)\n",
    "    parser.add_argument('-hl', '--hyperparameter_list', nargs='+', help='List of hyperparameters to search for', required=True)\n",
    "    parser.add_argument('-r', '--range', nargs='+', help='Range of the hyperparameters to search for', required=True)\n",
    "    parser.add_argument('-a', '--algorithm_list', default = None, nargs='+', help='List of algorithms to search for', required=False)\n",
    "    args = parser.parse_args()\n",
    "    main(args.template_folder, args.hyperparameter_list, args.range, args.algorithm_list)\n",
    "    sys.exit(0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bundle_root': None, 'ckpt_path': \"$@bundle_root + '/model'\", 'mlflow_tracking_uri': \"$@ckpt_path + '/mlruns/'\", 'mlflow_experiment_name': 'Auto3DSeg', 'data_file_base_dir': None, 'data_list_file_path': None, 'modality': 'mri', 'fold': 0, 'class_names': None, 'class_index': None, 'debug': False, 'ckpt_save': True, 'cache_rate': None, 'roi_size': [180, 240, 240], 'auto_scale_allowed': True, 'auto_scale_batch': True, 'auto_scale_roi': False, 'auto_scale_filters': False, 'quick': False, 'channels_last': True, 'validate_final_original_res': True, 'calc_val_loss': False, 'log_output_file': None, 'cache_class_indices': None, 'early_stopping_fraction': 0.001, 'stop_on_lowacc': False, 'training': {'amp': True, 'determ': False, 'input_channels': None, 'learning_rate': 0.0001, 'num_images_per_batch': 2, 'num_iterations': 40000, 'num_iterations_per_validation': 500, 'num_patches_per_image': 1, 'num_sw_batch_size': 2, 'output_classes': None, 'overlap_ratio': 0.625, 'patch_size': None, 'patch_size_valid': None, 'softmax': True, 'loss': {'_target_': 'DiceCELoss', 'include_background': True, 'squared_pred': True, 'smooth_nr': 0, 'smooth_dr': 1e-05, 'softmax': '$@training#softmax', 'sigmoid': '$not @training#softmax', 'to_onehot_y': '$@training#softmax', 'batch': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': '@training#learning_rate', 'weight_decay': 1e-05}, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.StepLR', 'optimizer': '$@training#optimizer', 'step_size': '$@training#num_iterations // 5', 'gamma': 0.5}}, 'batch_size': '@training#num_images_per_batch', 'num_epochs': 300, 'num_warmup_epochs': 3, 'resample': False, 'resample_resolution': [1, 1, 1], 'crop_mode': 'ratio', 'normalize_mode': 'meanstd', 'intensity_bounds': None, 'num_epochs_per_validation': None, 'num_epochs_per_saving': 1, 'num_workers': 4, 'num_steps_per_image': None, 'num_crops_per_image': 1, 'finetune': {'activate': False, 'pretrained_ckpt_name': \"$@bundle_root + '/model_fold' + str(@fold) + '/best_metric_model.pt'\"}, 'validate': {'enabled': False, 'ckpt_name': \"$@bundle_root + '/model/model.pt'\", 'output_path': \"$@bundle_root + '/prediction_validation'\", 'save_mask': False, 'invert': True}, 'infer': {'enabled': False, 'ckpt_name': \"$@bundle_root + '/model/model.pt'\", 'output_path': \"$@bundle_root + '/prediction_' + @infer#data_list_key\", 'data_list_key': 'testing'}}\n"
     ]
    }
   ],
   "source": [
    "hyps = get_hyperparameters('/var/data/student_home/lia/phuse_thesis_2024/monai_segmentation/DNN_models/algorithm_templates_yaml/UNET/configs/hyper_parameters.yaml')\n",
    "print(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
