{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import glob\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION IS NONE\n",
      "json_filename train_val3.json\n",
      "os.path.join(output_folder, json_filename) /var/data/student_home/lia/phuse_thesis_2024/monai_segmentation/monai_training/JSON_dir/train_val3.json\n",
      "file created\n",
      "DESCRIPTION IS NONE\n",
      "json_filename train_val.json\n",
      "os.path.join(output_folder, json_filename) ./JSON_dir/train_val.json\n",
      "file created\n"
     ]
    }
   ],
   "source": [
    "class WriteTrainJSON:\n",
    "    \"\"\"\n",
    "    Class for writing .json files to run from training from scratch, finetuning and/or the prediction of Choroid Plexus segmentations.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataroot: str=\".\", work_dir: str=\".\", description=None, train: str=\".\"):\n",
    "        \"\"\"\n",
    "        Initializes the class with the given parameters.\n",
    "\n",
    "        :param dataroot: The path to the data directory. (/var/data/MONAI_Choroid_Plexus/dataset_monai)\n",
    "        :param description: The description of the experiment.\n",
    "        :param work_dir: The working directory. (/var/data/student_home/lia/thesis/monai_segmentation/monai_training)\n",
    "        :param train: The path to the train directory.\n",
    "\n",
    "        Folderstructure is either: \n",
    "        --------------------------------\n",
    "        i_ChP.nii.gz\n",
    "        j_ChP.nii.gz\n",
    "        ...\n",
    "        labels\n",
    "            final\n",
    "                i_ChP.nii.gz\n",
    "                j_ChP.nii.gz\n",
    "                ...\n",
    "        --------------------------------\n",
    "        or \n",
    "        image_Tr\n",
    "            a_image.nii\n",
    "            b_image.nii\n",
    "            ...\n",
    "        image_Ts\n",
    "            i_image.nii\n",
    "            j_image.nii\n",
    "            ...\n",
    "        label_Tr\n",
    "            a_seg.nii\n",
    "            b_seg.nii\n",
    "            ...\n",
    "\n",
    "        where a, b, i, j are subject identifiers.   \n",
    "        \"\"\"\n",
    "        self.dataroot = dataroot\n",
    "        if description is None:\n",
    "            self.description='Dataset for Choroid Plexus segmentation'\n",
    "        elif isinstance(description, str):\n",
    "            self.description=description\n",
    "        self.work_dir = work_dir\n",
    "        self.train = train # maybe not needed\n",
    "\n",
    "        if not os.path.exists(self.dataroot):\n",
    "            raise ValueError(\"The path to the data directory does not exist. Please, provide the correct path.\")\n",
    "\n",
    "    def write_train_val_json(self, num_folds: int=5, train_val_ratio: float=0.5 , json_filename: str=\"train_val.json\"):\n",
    "\n",
    "        print(\"json_filename\", json_filename)\n",
    "\n",
    "        # Set path to output file\n",
    "        output_folder = os.path.join(self.work_dir, 'JSON_dir')\n",
    "\n",
    "        # Create output folder if it does not exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Check the folder structure\n",
    "        if os.path.exists(os.path.join(self.dataroot, 'labels')):\n",
    "            image_dir = self.dataroot\n",
    "            label_dir = os.path.join(self.dataroot, 'labels', 'final')\n",
    "        elif os.path.exists(os.path.join(self.dataroot, 'image_Tr')):\n",
    "            image_dir = os.path.join(self.dataroot, 'image_Tr')\n",
    "            label_dir = os.path.join(self.dataroot, 'label_Tr')\n",
    "        else:\n",
    "            print(\"self.dataroot\", self.dataroot)\n",
    "            raise ValueError(\"The folder structure is not correct. Please, provide the data in the correct format.\")\n",
    "\n",
    "        filenames_image = os.listdir(image_dir)\n",
    "        filenames_image.sort()\n",
    "        # Check if the label directory is in filenames_image and remove it from the list of filenames\n",
    "        if 'labels' in filenames_image:\n",
    "            filenames_image.remove('labels')\n",
    "    \n",
    "        filenames_label = os.listdir(label_dir)\n",
    "        filenames_label.sort()   \n",
    "\n",
    "        # remove hidden files and .DS_Store files \n",
    "        filenames_image = [f for f in filenames_image if not f.startswith('.')]\n",
    "        filenames_label = [f for f in filenames_label if not f.startswith('.')]\n",
    "\n",
    "        if len(filenames_image)!=len(filenames_label):\n",
    "            raise ValueError(\"The number of images and the number of labels is different. Please, check image_Tr and label_Tr folders.\")\n",
    "\n",
    "        image_paths = [os.path.join(image_dir, filename) for filename in filenames_image]\n",
    "        label_paths = [os.path.join(label_dir, filename) for filename in filenames_label]\n",
    "\n",
    "        # Check that all files have ending .nii or .nii.gz\n",
    "        for i in range(len(filenames_image)):\n",
    "            if not(filenames_image[i].endswith('.nii') | filenames_image[i].endswith('.nii.gz')):\n",
    "                raise ValueError(\"Data are not in the correct format. Please, provide images in .nii or .nii.gz Nifti format\")\n",
    "            if not(filenames_label[i].endswith('.nii') | filenames_label[i].endswith('.nii.gz')):\n",
    "                raise ValueError(\"Data are not in the correct format. Please, provide images in .nii or .nii.gz Nifti format\")\n",
    "            \n",
    "        # Split data into training and validation based on randomly sample jj indices \n",
    "        jj=math.ceil(len(filenames_image) * train_val_ratio) \n",
    "        random.seed(42) \n",
    "        indices = random.sample(range(len(filenames_image)), jj)\n",
    "\n",
    "        train_ids = [image_paths[i] for i in indices]\n",
    "        validation_ids = [image_paths[i] for i in range(len(filenames_image)) if i not in indices]\n",
    "        label_train_ids = [label_paths[i] for i in indices]\n",
    "        label_valid_ids = [label_paths[i] for i in range(len(filenames_label)) if i not in indices]        \n",
    "        \n",
    "        \n",
    "        # create json file - manually set\n",
    "        json_dict = OrderedDict()\n",
    "        json_dict['name'] = \"MRI Dataset - Choroid Plexus Segmentation\" \n",
    "        json_dict['description'] = self.description\n",
    "        json_dict['tensorImageSize'] = \"3D\"\n",
    "        json_dict['modality'] = {\n",
    "            \"0\": \"MR\"\n",
    "        }\n",
    "            \n",
    "        json_dict['labels'] = {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"Choroid Plexus\"\n",
    "        }\n",
    "\n",
    "        json_dict['numTraining'] = len(train_ids)\n",
    "        json_dict['numValidation'] = len(validation_ids)\n",
    "        json_dict['training'] = [{\"fold\": 0, \"image\": '%s' %i , \"label\": '%s' %j} for i, j in zip(train_ids, label_train_ids)]\n",
    "        json_dict['validation'] = [{\"image\": '%s' %i, \"label\": '%s' %j} for i,j in zip(validation_ids, label_valid_ids)]\n",
    "                \n",
    "        random.seed(42)\n",
    "        random.shuffle(json_dict[\"training\"])\n",
    "\n",
    "        # Split training data into N random folds\n",
    "        fold_size = len(json_dict[\"training\"]) // num_folds\n",
    "        for i in range(num_folds):\n",
    "            for j in range(fold_size):\n",
    "                json_dict[\"training\"][i * fold_size + j][\"fold\"] = i\n",
    "\n",
    "        print(\"os.path.join(output_folder, json_filename)\", os.path.join(output_folder, json_filename))\n",
    "        with open(os.path.join(output_folder, json_filename), 'w') as f:\n",
    "                json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "                print(\"file created\")\n",
    "                f.close()\n",
    "\n",
    "\n",
    "dataroot = \"/var/data/MONAI_Choroid_Plexus/dataset_monai_train_from_scratch\"\n",
    "work_dir = \"/var/data/student_home/lia/phuse_thesis_2024/monai_segmentation/monai_training\"\n",
    "json_file=WriteTrainJSON(dataroot, work_dir).write_train_val_json(json_filename = \"train_val3.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION IS NONE\n",
      "os.path.join(output_folder, json_filename) /var/data/student_home/lia/thesis/monai_segmentation/monai_training/JSON_dir/train_val.json\n",
      "file created\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def produce_sample_dict(line: str):\n",
    "    return {\"label\": line, \"image\": line.replace(\"labelsTr\", \"imagesTr\")}\n",
    "\n",
    "\n",
    "def produce_datalist(dataset_dir: str, train_size: int = 196):\n",
    "    \"\"\"\n",
    "    This function is used to split the dataset.\n",
    "    It will produce \"train_size\" number of samples for training.\n",
    "\n",
    "    Expected folder structure:\n",
    "    dataset_dir\n",
    "    ├── imagesTr\n",
    "    │   ├── subject1.nii.gz\n",
    "    │   ├── subject2.nii.gz\n",
    "    │   └── ...\n",
    "    └── labelsTr\n",
    "        ├── subject1.nii.gz\n",
    "        ├── subject2.nii.gz\n",
    "        └── ...\n",
    "\n",
    "    :param dataset_dir: The path to the dataset directory.\n",
    "    :param train_size: The number of samples to be used for training.\n",
    "    \"\"\"\n",
    "\n",
    "    samples = sorted(glob.glob(os.path.join(dataset_dir, \"labelsTr\", \"*\"), recursive=True))\n",
    "    samples = [_item.replace(os.path.join(dataset_dir, \"labelsTr\"), \"labelsTr\") for _item in samples]\n",
    "    datalist = []\n",
    "    for line in samples:\n",
    "        datalist.append(produce_sample_dict(line))\n",
    "    train_list, other_list = train_test_split(datalist, train_size=train_size)\n",
    "    val_list, test_list = train_test_split(other_list, train_size=0.66)\n",
    "\n",
    "    return {\"training\": train_list, \"validation\": val_list, \"testing\": test_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting launching_tool :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --dataroot DATAROOT\n",
      "                             [--description DESCRIPTION] --work_dir WORK_DIR\n",
      "                             [--training_dir TRAINING_DIR]\n",
      "                             [--train_json TRAIN_JSON]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --dataroot, --work_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class MyParser(argparse.ArgumentParser):\n",
    "    def error(self, message):\n",
    "        sys.stderr.write('error: %s\\n' % message)\n",
    "        self.print_help()\n",
    "        sys.exit(2)\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    print('Starting launching_tool :)')\n",
    "\n",
    "    # Initialize the parser\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Pipeline for training selected model from scratch or finetuning with N subjects with selected pretrained models\"\n",
    "    )\n",
    "\n",
    "    # Add the parameters positional/optional\n",
    "    parser.add_argument('--dataroot', required=True, default=\"/var/data/MONAI_Choroid_Plexus/dataset_train_from_scratch_monai\" , help=\"Data directory. Where the data is stored\")\n",
    "    parser.add_argument('--description', required=False, help=\"Data description\")\n",
    "    parser.add_argument('--work_dir', required=True, help=\"working directory\")\n",
    "    parser.add_argument('--training_dir', required=False, help=\"Working directory where to save trained models. If not specified, default folder name and locations will be used\")\n",
    "    parser.add_argument('--train_json', required=False, default=\"train_val.json\", help=\"Name of the .json file\")\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    " \n",
    "    print('Writing JSON file for training.....')\n",
    "    json_file=WriteTrainJSON(args.dataroot, args.description, args.work_dir, args.training_dir).write_train_val_json(json_filename=args.train_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
